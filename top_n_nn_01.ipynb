{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cf8dcd-6e76-4239-9dfa-3c339932e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (2.4.0)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (1.26.2)\n",
      "Requirement already satisfied: filelock in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.0 (from librosa)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting joblib>=0.14 (from librosa)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from lazy-loader>=0.1->librosa) (23.1)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.20.0->librosa)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/duncanroepke/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-macosx_11_0_arm64.whl (159 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, soxr, scipy, msgpack, llvmlite, lazy-loader, joblib, audioread, soundfile, scikit-learn, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 scikit-learn-1.5.2 scipy-1.14.1 soundfile-0.12.1 soxr-0.5.0.post1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafc7ea0-4323-45f4-af5e-b1502ef47041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import audioread\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8152384d-3b65-47f1-b896-c90e26cdf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert audio to Mel spectrogram using librosa\n",
    "def audio_to_melspectrogram(file_path, sr=22050, n_mels=64):\n",
    "    try:\n",
    "        # Use audioread to read the audio file\n",
    "        with audioread.audio_open(file_path) as input_file:\n",
    "            total_samples = input_file.samplerate * input_file.duration\n",
    "            y = np.zeros(int(total_samples))\n",
    "\n",
    "            i = 0\n",
    "            for buf in input_file:\n",
    "                buf_array = np.frombuffer(buf, dtype=np.int16) / 32768.0  # Convert buffer to float\n",
    "                y[i:i+len(buf_array)] = buf_array\n",
    "                i += len(buf_array)\n",
    "        \n",
    "        # If the sample rate is different from what we need, resample the audio\n",
    "        if input_file.samplerate != sr:\n",
    "            y = librosa.resample(y, input_file.samplerate, sr)\n",
    "\n",
    "        # Generate Mel Spectrogram\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        return spectrogram_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None  # In case of error, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efecb1b9-7765-44b7-a1ed-e7a00ec9205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Custom Dataset class to handle GTZAN data\n",
    "class GenreDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = audio_to_melspectrogram(self.file_paths[idx])\n",
    "        if spectrogram is None:\n",
    "            # Return None if the file is corrupted\n",
    "            return None\n",
    "        \n",
    "        spectrogram = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        spectrogram = F.interpolate(spectrogram.unsqueeze(0), size=(64, 64)).squeeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f55b15-4d08-4b62-b74e-3f39df61eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CNN Model for Genre Classification\n",
    "class GenreClassificationCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # GTZAN has 10 genres\n",
    "        super(GenreClassificationCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Can adjust based on input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d5adfb-1993-4f2e-a019-bf21f8a896fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Filter out corrupted files (None values)\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe7691d-3a5d-45d5-b1fc-ff7d3cad6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare GTZAN Dataset - Mapping genres to labels and loading the data\n",
    "def create_dataloader(audio_dir, batch_size=32):\n",
    "    genre_to_label = {\n",
    "        \"blues\": 0,\n",
    "        \"classical\": 1,\n",
    "        \"country\": 2,\n",
    "        \"disco\": 3,\n",
    "        \"hiphop\": 4,\n",
    "        \"jazz\": 5,\n",
    "        \"metal\": 6,\n",
    "        \"pop\": 7,\n",
    "        \"reggae\": 8,\n",
    "        \"rock\": 9\n",
    "    }\n",
    "    file_paths, labels = [], []\n",
    "    \n",
    "    # Traverse the GTZAN directories and gather file paths and labels\n",
    "    for genre in genre_to_label:\n",
    "        genre_folder = os.path.join(audio_dir, genre)\n",
    "        for file_name in os.listdir(genre_folder):\n",
    "            if file_name.endswith(\".wav\"):  # Only consider wav files\n",
    "                file_paths.append(os.path.join(genre_folder, file_name))\n",
    "                labels.append(genre_to_label[genre])\n",
    "\n",
    "    # Create Dataset and DataLoader\n",
    "    dataset = GenreDataset(file_paths, labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2b26bb-25ec-453d-8ed3-7242df6f89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training loop for the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Skip empty batches\n",
    "            if data is None:\n",
    "                continue\n",
    "            \n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch [{epoch + 1}], Batch [{i + 1}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d444c133-5b09-4be4-a42f-9eae5784b7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # 6. Path to the GTZAN dataset folder\n",
    "    audio_dir = \"/Users/duncanroepke/Downloads/Data/genres_original\"  # This point to the folder where \"blues\", \"classical\", etc. are located\n",
    "\n",
    "    # 7. Create DataLoader from GTZAN dataset\n",
    "    train_loader = create_dataloader(audio_dir, batch_size=32)\n",
    "\n",
    "    # 8. Initialize model, loss function, and optimizer\n",
    "    num_classes = 10  # GTZAN has 10 genres\n",
    "    model = GenreClassificationCNN(num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 9. Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "    # 10. Save the trained model\n",
    "    torch.save(model.state_dict(), \"genre_classification_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e492137-7135-4431-94e2-2056ef778aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
